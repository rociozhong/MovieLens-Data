# MovieLens-Data

For this project, I use MovieLens 100K Dataset (http://grouplens.org/datasets/movielens/ 100k/). The data set consists of 100,000 ratings (1-5) from 943 users on 1682 movies. Each user has rated at least 20 movies. The main data set, 'u.data', includes variables: user id, item id, rating and timestamp. And it has been split into five pairs of training and testing data sets (denoted by 'u1.base', 'u1.test',..., 'u5.base', 'u5.test'). The user information data includes the number of users, item id, and individual rating for a specific item. The user information dataset has demographical factors such as age, gender, occupation and zip code. The item information data consists of movie id, title. release date, and its genres.

The goal of this project is to predict preferences scores or ratings of each user. Given many missing values, I first try Matrix Factorization method to estimate the predictions. Then I tend to explore whether the missing ratings does occur at random. If not, I need to build a recommender system with a high accuracy of prediction, which demonstrate that the predictive performance can be enhanced based on informative missing values.

## Matrix Factorization

As its name suggests, matrix factorization is to find out two (or more) matrices such that when you multiply them you will get back the original matrix. From an application point of view, matrix factorization can be used to discover latent features underlying the interactions between two different kinds of entities. In our recommendation system case, each user have rated some movies, and I would like to predict how users would rate the movies that they have not rated yet. The intuition behind using matrix factorization to solve this problem is that there should be some latent features that determine how a user rates an item, such as a movie genre preferred by some users. Assuming the two latent features, through implementing the MF(Matrix Factorization) method, I get the RMSE?s values as 1.2214791611410365.

## Improvement

According to the dataset, there are 1682 movies, and each user at least rated 20 movies. But among them, some users rated far away beyond that, for instance, the maximum a movie get rated is 737. Thus, we might wonder why some people rated so many, but some only rated few. Do the missing ratings occur at random or not? To examine this, let us visualize the data and do some simple analysis. First, I plot a individual user versus their total rating numbers. There is a large variation among users, for example, a majority of users rated below 200 movies, and some are beyond 400 movies. In addition, we can notice there are more green points than red ones, indicating the majority of users are male (around 71\%). In order to assess whether there is difference between male and female users, I draw two plots (male versus female users). In this figure, we can tell that two genders have roughly the same distribution of ratings that most people have rated less than 100-150 movies, and few people rated more than 200 movies. Furthermore, I break down the ratings and calculate compare the percentage of male in each rating score category. Additionally, the percentage of male users for each rating score (1-5) is 69.0\%, 75.5\% 75.0\% 75.7\% and 71.8\% respectively. Given 71\% of data are male, it seems male are more willing to rate a movIe. Moreover, I look into whether age matters in the rating. The majority of users are fall between 20 and 40 years old. And once the age pass 20-25 years, as the age increases, the number of ratings decreases. In other words, younger people seems to give more movie ratings. Furthermore, I run a linear regression on the total number of ratings on age and gender, and the result, demonstrates that age and gender have some effects of movie rating numbers.

Based on the above, I've done some simple analyses and shown that age and gender might have effects on the rating number. Thus in this section, I tend to improve our prediction accuracy using content-based regression by adding age and gender factor into our method. Since the variable age and gender might have effects, for each movie i, I find its all corresponding observed ratings. Then I regress against the corresponding gender and age of a user from each rating score, and calculate beta i. If a movie i does not have enough ratings (less than 4), then I use the average of beta i from its five most similar movies, where similarity is measured based on movie's genres. Finally I get the RMSE with a value of 1.098533401136778, which is smaller than 1.2214791611410365 generated by the MF method.
